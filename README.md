# Multi-view 3D Reconstruction
This repo is for our course project for the course GNR 638. Our project is inspired by the paper [Robust Attentional Aggregation of Deep Feature Sets for Multi-view 3D Reconstruction](https://arxiv.org/abs/1808.00758). We have successfully implemented and tested the Attsets model and FASet algorithm proposed in the paper.

# Contents
1. The repo contains the notebook, **Multi_view_3D_Reconstruction.ipynb**. The notebook contains:
    1. The training model as class Network()
    2. The prediction code for testing the model

2. **data_loader.py**: For loading the dataset and carrying out certain operations on the dataset.
3. **binvox_rw**: 
4. The folder **Data_sample**: Contains the training dataset and original 3D Model for comparison.
5. The folder **Model_released**: 
6. LICENSE **Hyp**

# Papers
* [Robust Attentional Aggregation of Deep Feature Sets for Multi-view 3D Reconstruction](https://arxiv.org/abs/1808.00758)
* [3D-R2N2: A Unified Approach for Single and Multi-view 3D Object Reconstruction](https://arxiv.org/abs/1604.00449)
* [Learning a Multi-view stereo machine](https://arxiv.org/abs/1708.05375)
* [A Survey of Structure from Motion[SfM]](https://arxiv.org/abs/1701.08493)
* [Computer vision for Autonomous vehicles : Problems, Datasets and State of the Art](https://arxiv.org/abs/1704.05519)
